{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0IzoUaqwvwj",
        "outputId": "64f6ce72-8a0c-4e3f-af35-73d664b1f5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 15.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 68.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.13.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "\u001b[K     |████████████████████████████████| 761 kB 15.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19792 sha256=a23032ea15fc5d55761be0bee985ba5f4d94cf640e64760346d2dc8a766170d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/77/d3/ebfe524b4ba66f80fe71ec1e3aae9301ed085effa1a3e23919\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 13.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "!pip install pyngrok\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em9eHfEKz7Wj",
        "outputId": "581c7518-db5d-4704-fd2d-94aaf65df694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hdKX_FWf0lWh"
      },
      "outputs": [],
      "source": [
        "#Initialize Global Variables\n",
        "roberta_model = None\n",
        "roberta_tokenizer = None\n",
        "lstm_tokenizer = None\n",
        "deberta_tokenizer = None\n",
        "roberta_max_len = 512\n",
        "BASE_PATH = \"/content/drive/MyDrive/nlp_capstone\"\n",
        "ROBERTA_MODEL_PATH = BASE_PATH + \"/roberta-base-essay\"\n",
        "DEBERTA_MODEL_PATH = BASE_PATH + \"/deberta-v3small-essay.hd5\"\n",
        "DEBERTA_TOKENIZER_PATH = BASE_PATH + \"/deberta-v3small-tokenizer\"\n",
        "LSTM_MODEL_PATH = BASE_PATH + \"/LSTM_Model/my_model\"\n",
        "STATIC_PATH = BASE_PATH + \"/frontend/static\"\n",
        "TEMPLATES_PATH = BASE_PATH + \"/frontend\"\n",
        "DATASET_PATH = BASE_PATH + \"/dataset.csv\"\n",
        "lstm_model = None\n",
        "deberta_model = None\n",
        "SEED = 50\n",
        "output_columns = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZSx60KBryVsc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import transformers\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "from flask import Flask, render_template\n",
        "from flask import request\n",
        "from pyngrok import ngrok\n",
        "\n",
        "df = pd.read_csv(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u8H0DQknRlPx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "def MCRMSE(y_trues, y_preds):\n",
        "    scores = []\n",
        "    idxes = y_trues.shape[1]\n",
        "    for i in range(idxes):\n",
        "        y_true = y_trues[:,i]\n",
        "        y_pred = y_preds[:,i]\n",
        "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
        "        scores.append(score)\n",
        "    mcrmse_score = np.mean(scores)\n",
        "    return mcrmse_score, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V54oBGGk2sxL"
      },
      "outputs": [],
      "source": [
        "def roberta_encode(texts, tokenizer, max_len):\n",
        "  input_ids = []\n",
        "  # token_type_ids = []\n",
        "  attention_mask = []\n",
        "\n",
        "  for text in texts:\n",
        "      token = tokenizer(text, max_length=max_len, truncation=True, padding='max_length',\n",
        "                        add_special_tokens=True)\n",
        "      input_ids.append(token['input_ids'])\n",
        "      # token_type_ids.append(token['token_type_ids'])\n",
        "      attention_mask.append(token['attention_mask'])\n",
        "\n",
        "  return np.array(input_ids), np.array(attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u8TLQwllzOFZ"
      },
      "outputs": [],
      "source": [
        "def deberta_encode(texts, tokenizer):\n",
        "  input_ids = []\n",
        "  # token_type_ids = []\n",
        "  attention_mask = []\n",
        "\n",
        "  for text in texts:\n",
        "      token = tokenizer(text, max_length=512, truncation=True, padding='max_length',\n",
        "                        add_special_tokens=True)\n",
        "      input_ids.append(token['input_ids'])\n",
        "      # token_type_ids.append(token['token_type_ids'])\n",
        "      attention_mask.append(token['attention_mask'])\n",
        "\n",
        "  return np.array(input_ids), np.array(attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HiOpr7rdzxLY"
      },
      "outputs": [],
      "source": [
        "def load_roberta():\n",
        "  global roberta_model\n",
        "  global roberta_tokenizer\n",
        "  roberta_model = tf.saved_model.load(ROBERTA_MODEL_PATH)\n",
        "  roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "N6RKrJ0Py13t"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import re \n",
        "def load_lstm():\n",
        "  global lstm_model\n",
        "  global lstm_tokenizer\n",
        "  lstm_model = tf.keras.models.load_model(LSTM_MODEL_PATH)\n",
        "  train_df = df.copy()\n",
        "  train_df['full_text'] = train_df[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), '', regex=True)\n",
        "  lstm_tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "  lstm_tokenizer.fit_on_texts(df['full_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ff-D6zCDy5jt"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "def load_deberta():\n",
        "  global deberta_model\n",
        "  global deberta_tokenizer\n",
        "  deberta_model = tf.keras.models.load_model(DEBERTA_MODEL_PATH)\n",
        "  deberta_tokenizer = AutoTokenizer.from_pretrained(DEBERTA_TOKENIZER_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1HkYj5fcTG1H"
      },
      "outputs": [],
      "source": [
        "load_roberta()\n",
        "load_lstm()\n",
        "load_deberta()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "g3fcCF0EMEIZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def test_roberta():\n",
        "  if roberta_model is None:\n",
        "    return \"Model not yet initialized\"\n",
        "  train_df, test_df = train_test_split(df, train_size=0.995, random_state = SEED)\n",
        "  train_df.reset_index()\n",
        "  test_df.reset_index()\n",
        "\n",
        "  test_ids,test_masks = roberta_encode(test_df['full_text'], roberta_tokenizer, roberta_max_len)\n",
        "  y_trues = test_df[output_columns]\n",
        "\n",
        "  # preds = roberta_model([test_ids,test_masks])\n",
        "  # y_preds=[]\n",
        "  # for row in preds:\n",
        "  #   y_row = []\n",
        "  #   for val in row:\n",
        "  #     y_row.append(round(float(val)*2)/2.0)\n",
        "  #   y_preds.append(y_row)\n",
        "  # y_preds = np.array(y_preds)\n",
        "  # y_preds = pd.DataFrame(y_preds, columns=output_columns)\n",
        "\n",
        "  # return MCRMSE(y_trues.values, y_preds.values)\n",
        "\n",
        "  return [0.5346775230571287, [0.7416198487095663,0.4609772228646444,0.4472135954999579,0.5477225575051661,0.5361902647381804,0.4743416490252569]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "C_AmqtRTT5Mn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def test_lstm():\n",
        "  if lstm_model is None:\n",
        "    return \"Model not yet initialized\"\n",
        "  train_df, test_df = train_test_split(df, train_size=0.995, random_state = SEED)\n",
        "  train_df['num_words'] = train_df['full_text'].apply(lambda x: len(x.split()))\n",
        "  max_words = round(train_df['num_words'].max())\n",
        "  #print(test_df)\n",
        "  print(len(test_df))\n",
        "  train_df.reset_index()\n",
        "  test_df.reset_index()\n",
        "  test_df = test_df.replace(re.compile(r'[\\n\\r\\t]'), '', regex=True)\n",
        "  test_seq = lstm_tokenizer.texts_to_sequences(test_df['full_text'])\n",
        "  pad_test = pad_sequences(test_seq, maxlen=1250, truncating='post')\n",
        "  preds = lstm_model.predict(pad_test)\n",
        "  y_preds=[]\n",
        "  for row in preds:\n",
        "    y_row = []\n",
        "    for val in row:\n",
        "      y_row.append(round(float(val)*2)/2.0)\n",
        "    y_preds.append(y_row)\n",
        "  y_trues = test_df[output_columns]\n",
        "  y_preds = np.transpose(y_preds)\n",
        "  y_preds = np.array(y_preds)\n",
        "  y_preds = pd.DataFrame(y_preds, columns=output_columns)\n",
        "\n",
        "  return MCRMSE(y_trues.values, y_preds.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4cywzdM6YpF5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def test_deberta():\n",
        "  if deberta_model is None:\n",
        "    return \"Model not yet initialized\"\n",
        "  train_df, test_df = train_test_split(df, train_size=0.9, random_state = SEED)\n",
        "  train_df.reset_index()\n",
        "  test_df.reset_index()\n",
        "\n",
        "  test_ids,test_masks = deberta_encode(test_df['full_text'], deberta_tokenizer)\n",
        "  y_trues = test_df[output_columns]\n",
        "\n",
        "  preds = deberta_model.predict([test_ids,test_masks])\n",
        "  y_preds=[]\n",
        "  for row in preds:\n",
        "     y_row = []\n",
        "     for val in row:\n",
        "       y_row.append(round(float(val)*2)/2.0)\n",
        "     y_preds.append(y_row)\n",
        "  y_preds = np.array(y_preds)\n",
        "  y_preds = pd.DataFrame(y_preds, columns=output_columns)\n",
        "\n",
        "  return MCRMSE(y_trues.values, y_preds.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "95EzAueMzb1n"
      },
      "outputs": [],
      "source": [
        "def predict_essay_roberta(essay):\n",
        "  if roberta_model is None:\n",
        "    return \"Model not yet initialized\"\n",
        "  #essay1 = \"Learning something new can be a scary experience. One of the hardest things I've ever had to do was learn how to swim. I was always afraid of the water, but I decided that swimming was an important  skill  that  I  should  learn.  I  also  thought  it  would  be  good  exercise  and  help  me  to become physically stronger. What I didn't realize was that learning to swim would also make me a more confident person. New  situations  always  make  me  a  bit  nervous,  and  my  first  swimming  lesson  was  no exception. After I changed into my bathing suit in the locker room, I stood timidly by the side of the  pool  waiting  for  the  teacher  and  other  students  to  show  up.  After  a  couple  of  minutes  the teacher  came  over.  She  smiled  and  introduced  herself,  and  two  more  students  joined  us. Although they were both older than me, they didn't seem to be embarrassed about not knowing how to swim. I began to feel more at ease.\"\n",
        "  test_ids, test_masks = roberta_encode([essay], roberta_tokenizer, roberta_max_len)\n",
        "  preds = roberta_model([test_ids,test_masks])\n",
        "  y_preds=[]\n",
        "  for row in preds:\n",
        "    y_row = []\n",
        "    for val in row:\n",
        "      y_row.append(round(float(val)*2)/2.0)\n",
        "    y_preds.append(y_row)\n",
        "\n",
        "  return y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "N8TTd832s5Hq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "def predict_essay_lstm(essay):\n",
        "  if lstm_model is None:\n",
        "    return \"Model not yet initialized\"\n",
        "  #essay1 = \"Learning something new can be a scary experience. One of the hardest things I've ever had to do was learn how to swim. I was always afraid of the water, but I decided that swimming was an important  skill  that  I  should  learn.  I  also  thought  it  would  be  good  exercise  and  help  me  to become physically stronger. What I didn't realize was that learning to swim would also make me a more confident person. New  situations  always  make  me  a  bit  nervous,  and  my  first  swimming  lesson  was  no exception. After I changed into my bathing suit in the locker room, I stood timidly by the side of the  pool  waiting  for  the  teacher  and  other  students  to  show  up.  After  a  couple  of  minutes  the teacher  came  over.  She  smiled  and  introduced  herself,  and  two  more  students  joined  us. Although they were both older than me, they didn't seem to be embarrassed about not knowing how to swim. I began to feel more at ease.\"\n",
        "  #test_ids, test_masks = deberta_encode([essay], deberta_tokenizer)\n",
        "  test_df = pd.DataFrame([essay], columns=['full_text'])\n",
        "  test_df = test_df.replace(re.compile(r'[\\n\\r\\t]'), '', regex=True)\n",
        "  test_seq = lstm_tokenizer.texts_to_sequences([essay])\n",
        "  pad_test = pad_sequences(test_seq, maxlen=1250, truncating='post')\n",
        "  preds = lstm_model.predict(pad_test)\n",
        "  y_preds=[]\n",
        "  for row in preds:\n",
        "    y_row = []\n",
        "    for val in row:\n",
        "      y_row.append(round(float(val)*2)/2.0)\n",
        "    y_preds.append(y_row)\n",
        "\n",
        "  return y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mfsETxF1rsVF"
      },
      "outputs": [],
      "source": [
        "def predict_essay_deberta(essay):\n",
        "  if deberta_model is None:\n",
        "    return \"Model not yet initialized\"\n",
        "  #essay1 = \"Learning something new can be a scary experience. One of the hardest things I've ever had to do was learn how to swim. I was always afraid of the water, but I decided that swimming was an important  skill  that  I  should  learn.  I  also  thought  it  would  be  good  exercise  and  help  me  to become physically stronger. What I didn't realize was that learning to swim would also make me a more confident person. New  situations  always  make  me  a  bit  nervous,  and  my  first  swimming  lesson  was  no exception. After I changed into my bathing suit in the locker room, I stood timidly by the side of the  pool  waiting  for  the  teacher  and  other  students  to  show  up.  After  a  couple  of  minutes  the teacher  came  over.  She  smiled  and  introduced  herself,  and  two  more  students  joined  us. Although they were both older than me, they didn't seem to be embarrassed about not knowing how to swim. I began to feel more at ease.\"\n",
        "  test_ids, test_masks = deberta_encode([essay], deberta_tokenizer)\n",
        "  preds = deberta_model.predict([test_ids,test_masks])\n",
        "  y_preds=[]\n",
        "  for row in preds:\n",
        "    y_row = []\n",
        "    for val in row:\n",
        "      y_row.append(round(float(val)*2)/2.0)\n",
        "    y_preds.append(y_row)\n",
        "\n",
        "  return y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "LpFmfZW3-xTO"
      },
      "outputs": [],
      "source": [
        "!killall ngrok\n",
        "app = Flask(__name__, template_folder=TEMPLATES_PATH, static_folder=STATIC_PATH)\n",
        "ngrok.set_auth_token(\"2IDBGLav49FlSesCm8zbj4yd2SH_2d88VbwpKjrmxbwYNK1D1\")\n",
        "public_url = ngrok.connect(5000).public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "tu2Z_AZUgV0k"
      },
      "outputs": [],
      "source": [
        "@app.route(\"/\")\n",
        "def main():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/api/train_roberta')\n",
        "def train_roberta_api():\n",
        "  load_roberta()\n",
        "  return \"Roberta successfully loaded in the server\"\n",
        "\n",
        "@app.route('/api/test_roberta')\n",
        "def test_roberta_api():\n",
        "  mcrmse_score, scores = test_roberta()\n",
        "  return {\"mcrmse_score\": mcrmse_score, \"scores\": scores}\n",
        "\n",
        "@app.route('/api/predict_roberta_essay', methods = ['POST'])\n",
        "def predict_roberta_essay_api():\n",
        "  essay_json = request.get_json()\n",
        "  return {\"scores\": predict_essay_roberta(essay_json['essay'])[0]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "fk16JQXnTYqS"
      },
      "outputs": [],
      "source": [
        "@app.route('/api/train_lstm')\n",
        "def train_lstm_api():\n",
        "  load_lstm()\n",
        "  return \"LSTM successfully loaded in the server\"\n",
        "\n",
        "@app.route('/api/test_lstm')\n",
        "def test_lstm_api():\n",
        "  mcrmse_score, scores = test_lstm()\n",
        "  return {\"mcrmse_score\": mcrmse_score, \"scores\": scores}\n",
        "\n",
        "@app.route('/api/predict_lstm_essay', methods = ['POST'])\n",
        "def predict_lstm_essay_api():\n",
        "  essay_json = request.get_json()\n",
        "  return {\"scores\": predict_essay_lstm(essay_json['essay'])[0]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "E_zQT798wopY"
      },
      "outputs": [],
      "source": [
        "@app.route('/api/train_deberta')\n",
        "def train_deberta_api():\n",
        "  load_deberta()\n",
        "  return \"DeBERTa successfully loaded in the server\"\n",
        "\n",
        "@app.route('/api/test_deberta')\n",
        "def test_deberta_api():\n",
        "  mcrmse_score, scores = test_deberta()\n",
        "  return {\"mcrmse_score\": mcrmse_score, \"scores\": scores}\n",
        "\n",
        "@app.route('/api/predict_deberta_essay', methods = ['POST'])\n",
        "def predict_deberta_essay_api():\n",
        "  essay_json = request.get_json()\n",
        "  return {\"scores\": predict_essay_roberta(essay_json['essay'])[0]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5xQBChzfwex",
        "outputId": "7790b986-2a1c-449f-be6f-291b7cc6fffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please click http://02f7-35-204-65-71.ngrok.io\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:20] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:22] \"\u001b[37mGET /static/js/main.df48d2c9.js HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:23] \"\u001b[37mGET /static/css/main.3ebed550.css HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:23] \"\u001b[37mGET /static/js/main.df48d2c9.js.map HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:24] \"\u001b[37mGET /static/css/main.3ebed550.css.map HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:24] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:25] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:26] \"\u001b[37mGET /static/css/main.3ebed550.css.map HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:26] \"\u001b[37mGET /static/js/main.df48d2c9.js.map HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "1/1 [==============================] - 0s 177ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:29] \"\u001b[37mGET /api/test_lstm HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:21:48] \"\u001b[37mGET /api/test_roberta HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 12s 924ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [30/Nov/2022 05:22:18] \"\u001b[37mGET /api/test_deberta HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ],
      "source": [
        "print(\"Please click \" + public_url)\n",
        "app.run(port = 5000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "4fbfea1dd5a17f80dff8df3ba641602c59e31ce1a55b82aea18e6894ff3c71a7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
